
\documentclass[12pt]{article}
\usepackage{jmiremu}
\usepackage[toc,page]{appendix} % in the preamble

\title{HPH Framework: Research Project Plan}
\author[1]{Ivan Ogasawara}
\affil[1]{Independent Researcher, IGDORE}
\date{November 2025}

\begin{document}
\maketitle

\section{Background and Rationale}
High-quality clinical care hinges on continuity and accessibility of
information across the entire encounter: screening, diagnosis, treatment,
prescription, and follow-up. Despite major gains in electronic health record
(EHR) adoption over the past decade, fragmentation and workflow misalignment
persist in practice. For example, U.S. office-based physician EHR adoption
reached 88.2\% in 2021 \cite{cdc_nehrs_2021}, and sector-specific settings
(e.g., assisted living communities) have also seen rapid growth in EHR and
health information exchange (HIE) functions \cite{lin2022jamia}. Pre-pandemic
assessments document a decade of progress (2009--2019), but also reveal gaps
in interoperability and use that impact team coordination \cite{jiang2023}.

Concurrently, artificial intelligence (AI)---including large language models
(LLMs), retrieval-augmented generation (RAG), and multimodal learning---is
increasingly applied to clinical decision support (CDS). Recent reviews
highlight both emerging utility and persistent adoption barriers, including
trust, explainability, and workflow fit \cite{tun2025trust,bmc_hf_2024,
simon2025mmai}. Most existing systems remain narrow, supporting a single step
(e.g., triage, risk prediction, imaging) rather than the longitudinal,
multidisciplinary workflow clinicians require.

\subsection*{Context: National deployments (DoctorSV)}
Recent national initiatives such as El Salvador’s DoctorSV signal momentum
toward unified digital health services and a ``single clinical history''
vision. Public communications describe phased onboarding and integration
with pharmacies, laboratories, and imaging providers. While independent
evaluations are pending, these programs underscore the need for modular,
standards-aligned, and auditable AI frameworks that can integrate with
national infrastructures \cite{caf2025doctorsv}.

\section{Significance and Innovation}
The project contributes to medical informatics by:
\begin{itemize}
  \item Integrating multimodal AI components across screening-to-follow-up
  within one longitudinal workflow.
  \item Embedding transparency, provenance, and human oversight into each AI
  interaction (audit trails, citations, model cards).
  \item Providing a plug-in architecture compatible with FHIR and open data
  models, enabling site-specific extensibility.
  \item Addressing trust, usability, and task--technology fit from the outset
  through mixed-methods evaluation with clinicians.
\end{itemize}

\subsection*{Implications for national platforms}
Although our evaluation uses synthetic cases in a research prototype,
the framework’s emphasis on FHIR compatibility, provenance/audit logs,
and modular AI suggests a natural path for integration with emerging
national platforms (e.g., DoctorSV), contingent on available interfaces,
governance agreements, and safety validation. We did not analyze or
evaluate any national deployment; references to such programs are purely
contextual.

\section{Objectives and Research Questions}
\textbf{Primary research question:} How can an AI-augmented, EHR-centered
framework improve information continuity and perceived decision support across
multidisciplinary care?

\noindent\textbf{Secondary research questions:}
\begin{enumerate}
  \item Which design principles enable effective multi-phase AI integration?
  \item How do clinicians perceive trust, explainability, usability, and
  workflow fit when using the framework?
  \item What technical and organizational challenges arise during early
  adoption in simulated settings?
\end{enumerate}

\section{Conceptual Framework}
We model the encounter as five interconnected stages:
\begin{enumerate}
  \item \textbf{Screening \& Triage:} symptom capture, patient-reported
  information, AI-assisted risk estimation.
  \item \textbf{Diagnostic Reasoning:} multimodal data integration and
  differential support with literature-backed rationale.
  \item \textbf{Treatment Planning:} guideline-aware plan synthesis and
  safety checks (e.g., interactions).
  \item \textbf{Prescription \& Care Execution:} structured orders and care
  plans documented within the unified record.
  \item \textbf{Follow-up \& Prognosis:} monitoring, prediction, and
  longitudinal review.
\end{enumerate}
A unified longitudinal record maintains structured fields (labs, vitals,
medications), unstructured notes, and AI-generated artifacts with provenance.

\section{Methodology}
\subsection{Study Design}
A mixed-methods, within-subjects, counterbalanced study combining iterative
system development with early evaluation using synthetic cases and clinician
participants.

\subsection{Baseline Workflow (Standard): OpenMRS Reference Application}
The baseline condition uses the OpenMRS Reference Application (RefApp) with
the FHIR2 module (FHIR R4). We will load the same synthetic cases used in the
HPH condition into OpenMRS via FHIR Bundle POSTs. Baseline sessions disable
any decision-support or AI add-ons. Participants interact with standard
OpenMRS views for: Notes, Labs, Medications, Imaging/Reports, and a patient
timeline. Role-based accounts (IM/FP, EM, Psychiatry) will have read/enter
permissions appropriate for data review and note entry.

\subsection{HPH Workflow (Prototype)}
The HPH condition uses our prototype UI backed by the identical FHIR Bundles.
The prototype renders the same clinical content and adds assistive features
(e.g., structured summaries, literature-backed suggestions, provenance). The
prototype does not expose information unavailable in the baseline.

\subsection{Parity Rules (Pre-registered)}
We enforce parity to isolate the effect of the framework:
\begin{itemize}
  \item \textbf{Seeding and interaction:} Both conditions use the identical
  canonical FHIR R4 Bundle per case; OpenMRS is pre-seeded via FHIR2
  (pre-session), and the HPH prototype reads the same Bundle. Clinicians
  interact only through the respective UIs; no data are entered during sessions.
  \item \textbf{Content parity:} identical synthetic cases, timestamps, and
  missingness patterns in both conditions.
  \item \textbf{Task parity:} identical task lists (e.g., initial orders, risk
  estimate, disposition).
  \item \textbf{Time parity:} matched time windows per block.
  \item \textbf{Feature parity:} no decision-support in baseline; assistive
  features in HPH are labeled and auditable.
\end{itemize}

\subsection{Synthetic Case Generation and Artifact Pipeline}
Two EHR-formatted vignettes (acute and chronic multimorbidity) will be
constructed from guidelines/textbooks and refined by 2--3 clinicians. Each
case is authored as a canonical \textbf{FHIR R4 Bundle} (Patient, Encounter,
Observation for labs/vitals, MedicationStatement/Request, DiagnosticReport for
ECG/CXR text, ImagingStudy metadata, AllergyIntolerance, CarePlan,
Composition). From the Bundle we derive UI artifacts for both conditions:
\begin{itemize}
  \item \textbf{OpenMRS baseline:} create records via FHIR POSTs; use native
  OpenMRS views for review.
  \item \textbf{HPH prototype:} read the same Bundle to render equivalent
  views plus assistive summaries.
\end{itemize}
Each case folder contains a manifest (hashes, counts of resources) and frozen
version to ensure reproducibility.

\subsection{Participants}
We will recruit 6--12 physicians across specialties (e.g., internal medicine,
family medicine, emergency, psychiatry). Inclusion criteria: licensed MD, $\geq$
1 year of routine EHR use. Exclusion: prior contribution to this study's
prototype design beyond informal feedback.

\subsection{Session Flow and Counterbalancing}
Each participant completes both cases under both workflows. Order is
counterbalanced across participants (Latin square: Case A/B $\times$ Baseline/HPH).
A typical session (40--60 minutes): consent and orientation; Block~1 (case~$\times$
workflow); Block~2 (the alternate workflow on the same case); repeat for the
second case; questionnaires and short interview.

\subsection{Measures}
\textbf{Quantitative (5-point Likert):} perceived usefulness, decision-support
quality, information continuity, explainability, workflow fit; optional
NASA-TLX workload. \textbf{Qualitative:} interview themes on strengths,
limitations, collaborative use, and safety.

\subsection{Analysis}
Wilcoxon signed-rank tests (and effect sizes) compare framework-assisted
versus baseline workflows within-subjects. Thematic analysis (inductive
coding) is applied to interview transcripts. Mixed-methods triangulation
integrates quantitative and qualitative findings.

\section{Ethical Considerations}
No real patient data will be collected or analyzed. Vignettes are synthetic
and de-identified. Clinicians (the only human participants) will provide
informed consent. The protocol will be submitted to an institutional ethics
committee to confirm compliance with regulations for studies involving
clinicians and simulated cases.

\section{Risk Management}
Risks include data misuse, overreliance on AI suggestions, and participant
fatigue. Mitigations: strict separation from real EHRs; clear labeling of AI
outputs as assistive; capped session length; and audit trails for all AI
artifacts.

\section{Timeline}
\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Phase} & \textbf{Duration \& Key Tasks} \\
\midrule
Design \& Requirements & Months 1--3: literature review; architecture; IRB prep. \\
Prototype Development & Months 4--6: build plugins; unify record; interface. \\
Evaluation & Months 7--8: clinician sessions; data collection. \\
Analysis \& Writing & Months 9--10: analysis; manuscript; preregistration. \\
\bottomrule
\end{tabular}
\end{table}

\section{Dissemination Plan}
We will prepare a preprint and target a digital health venue (e.g., JMIR AI,
JAMIA Open, Frontiers in Digital Health). Open-source components that do not
process patient data will be released under a permissive license, with
documentation and demo notebooks.

\section{Code and Data Availability}
All non-proprietary software components and study protocols will be released
under a permissive open-source license (e.g., BSD-3-Clause). A code
availability statement will be included as recommended by JMIR
\cite{jmir_data_policy2025}, with repository URL and an archived DOI
(immutable release) cited in the manuscript.

\section{Expected Outcomes}
\begin{itemize}
  \item A validated conceptual and technical framework for AI-integrated
  encounters.
  \item A working prototype demonstrating cross-phase AI interoperability.
  \item Empirical insights into clinician trust, explainability, and workflow
  integration in simulated studies.
\end{itemize}

\section{References}
\bibliographystyle{unsrt}
\bibliography{references}

\clearpage
\begin{appendices}
  \input{appendix_vignette}
  \clearpage
  \input{appendix_interaction}
\end{appendices}

\end{document}
